{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Hu9CJcZVRD31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJNPnCRKQ4ZH",
        "outputId": "5361b1e0-e34e-42d6-bfe5-7dca8484b833"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m122.9/176.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HZKWDRStOnfU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIxDNzbLQ2Xd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Data"
      ],
      "metadata": {
        "id": "pQVavbsGRFbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Origial folder location\n",
        "data_scr_dir = '/content/drive/MyDrive/Flatiron/Phase 5/Data'\n",
        "\n",
        "\n",
        "data_dst_folder = '/content/data'\n",
        "\n",
        "\n",
        "# copy folder from location to local storage\n",
        "\n",
        "shutil.copytree(data_scr_dir, data_dst_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8paRLSAxQuT0",
        "outputId": "30e2cd14-614f-4181-ba0c-2ae3964cf31a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the paths and class labels\n",
        "data_dir = '/content/data'\n",
        "class_labels = ['VeryMildDemented', 'ModerateDemented', 'MildDemented', 'NonDemented']\n",
        "image_size = (28, 28) # Desired image size"
      ],
      "metadata": {
        "id": "2HpXrSFCV-vr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images and labels:\n",
        "img = []\n",
        "lbl = []\n",
        "\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    folder_path = os.path.join(data_dir, label)\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file) # get the image\n",
        "        image = cv2.imread(image_path) # read the image\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        image = cv2.resize(image, image_size)  # Resize the image\n",
        "        img.append(image)\n",
        "        lbl.append(label_idx)"
      ],
      "metadata": {
        "id": "ZTiEXSArViOd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.array(img)\n",
        "label = np.array(lbl)"
      ],
      "metadata": {
        "id": "D9BLcyowWLK3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into train and test data sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "q7uMRLeCWNKv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCN6DI0VZ4tw",
        "outputId": "19ec302c-2a03-4e73-fcc1-0e4548ad978d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27194, 28, 28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model"
      ],
      "metadata": {
        "id": "bsMKsKcvZUpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import activations\n",
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28,3)))\n",
        "\n",
        "  for i in range(hp.Int('layers', 2, 20)):\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=hp.Int('units', min_value=8, max_value=512, step=32),\n",
        "        activation = hp.Choice('act_', values=['relu'])\n",
        "        ))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4idpV4CsZHgf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=20,\n",
        "                     factor=3,\n",
        "                     directory='HyperBand_Dir_v3',\n",
        "                     project_name='Alzheimer_Image_Tuner')"
      ],
      "metadata": {
        "id": "V7l2XP3cZWSj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "VGckp2YeZYBW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtHIR1gEZaMC",
        "outputId": "2010a791-63a4-466c-ca18-9d9894efa4d4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 51s]\n",
            "val_accuracy: 0.4642397463321686\n",
            "\n",
            "Best val_accuracy So Far: 0.7712814807891846\n",
            "Total elapsed time: 00h 17m 48s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 424 and the optimal learning rate for the optimizer\n",
            "is 0.0001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "KGzplmTUaN-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXGT7D8OZgPg",
        "outputId": "325a197e-e245-482e-813d-2026fedf5eb3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "680/680 [==============================] - 7s 6ms/step - loss: 1.2788 - accuracy: 0.4080 - val_loss: 1.0386 - val_accuracy: 0.4970\n",
            "Epoch 2/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 1.0127 - accuracy: 0.5232 - val_loss: 0.9535 - val_accuracy: 0.5510\n",
            "Epoch 3/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.9481 - accuracy: 0.5549 - val_loss: 0.8727 - val_accuracy: 0.5878\n",
            "Epoch 4/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.8956 - accuracy: 0.5786 - val_loss: 0.8500 - val_accuracy: 0.6019\n",
            "Epoch 5/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.8519 - accuracy: 0.6018 - val_loss: 0.8759 - val_accuracy: 0.5780\n",
            "Epoch 6/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.8069 - accuracy: 0.6280 - val_loss: 0.8545 - val_accuracy: 0.5872\n",
            "Epoch 7/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.7705 - accuracy: 0.6452 - val_loss: 0.7530 - val_accuracy: 0.6520\n",
            "Epoch 8/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.7345 - accuracy: 0.6640 - val_loss: 0.7595 - val_accuracy: 0.6327\n",
            "Epoch 9/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.6941 - accuracy: 0.6790 - val_loss: 0.8461 - val_accuracy: 0.6431\n",
            "Epoch 10/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.6620 - accuracy: 0.6979 - val_loss: 0.6897 - val_accuracy: 0.7014\n",
            "Epoch 11/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.6302 - accuracy: 0.7147 - val_loss: 0.6636 - val_accuracy: 0.7027\n",
            "Epoch 12/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.6018 - accuracy: 0.7279 - val_loss: 0.6706 - val_accuracy: 0.6998\n",
            "Epoch 13/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.5716 - accuracy: 0.7446 - val_loss: 0.6868 - val_accuracy: 0.6953\n",
            "Epoch 14/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7594 - val_loss: 0.6470 - val_accuracy: 0.7141\n",
            "Epoch 15/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.5086 - accuracy: 0.7743 - val_loss: 0.7272 - val_accuracy: 0.7031\n",
            "Epoch 16/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.4885 - accuracy: 0.7838 - val_loss: 0.7555 - val_accuracy: 0.7040\n",
            "Epoch 17/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4766 - accuracy: 0.7937 - val_loss: 0.5458 - val_accuracy: 0.7636\n",
            "Epoch 18/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4433 - accuracy: 0.8039 - val_loss: 0.5976 - val_accuracy: 0.7422\n",
            "Epoch 19/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.4200 - accuracy: 0.8183 - val_loss: 0.5582 - val_accuracy: 0.7661\n",
            "Epoch 20/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3998 - accuracy: 0.8278 - val_loss: 0.5812 - val_accuracy: 0.7614\n",
            "Epoch 21/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3895 - accuracy: 0.8326 - val_loss: 0.7029 - val_accuracy: 0.7189\n",
            "Epoch 22/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3666 - accuracy: 0.8450 - val_loss: 0.6435 - val_accuracy: 0.7569\n",
            "Epoch 23/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.3501 - accuracy: 0.8509 - val_loss: 0.5802 - val_accuracy: 0.7713\n",
            "Epoch 24/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3383 - accuracy: 0.8615 - val_loss: 0.5951 - val_accuracy: 0.7674\n",
            "Epoch 25/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3148 - accuracy: 0.8707 - val_loss: 0.5862 - val_accuracy: 0.7773\n",
            "Epoch 26/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.3020 - accuracy: 0.8716 - val_loss: 0.6331 - val_accuracy: 0.7821\n",
            "Epoch 27/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2957 - accuracy: 0.8790 - val_loss: 0.6080 - val_accuracy: 0.7878\n",
            "Epoch 28/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2736 - accuracy: 0.8857 - val_loss: 0.5643 - val_accuracy: 0.7895\n",
            "Epoch 29/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2632 - accuracy: 0.8924 - val_loss: 0.6137 - val_accuracy: 0.7887\n",
            "Epoch 30/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.2544 - accuracy: 0.8950 - val_loss: 0.5802 - val_accuracy: 0.7709\n",
            "Epoch 31/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2389 - accuracy: 0.9030 - val_loss: 0.5957 - val_accuracy: 0.7884\n",
            "Epoch 32/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2299 - accuracy: 0.9073 - val_loss: 0.7257 - val_accuracy: 0.7599\n",
            "Epoch 33/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.2342 - accuracy: 0.9065 - val_loss: 0.5968 - val_accuracy: 0.8117\n",
            "Epoch 34/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2032 - accuracy: 0.9184 - val_loss: 0.7406 - val_accuracy: 0.7858\n",
            "Epoch 35/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1997 - accuracy: 0.9204 - val_loss: 0.5522 - val_accuracy: 0.8110\n",
            "Epoch 36/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2019 - accuracy: 0.9213 - val_loss: 0.6887 - val_accuracy: 0.7854\n",
            "Epoch 37/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1860 - accuracy: 0.9274 - val_loss: 0.6778 - val_accuracy: 0.7967\n",
            "Epoch 38/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1747 - accuracy: 0.9315 - val_loss: 0.6393 - val_accuracy: 0.8075\n",
            "Epoch 39/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1735 - accuracy: 0.9316 - val_loss: 0.6281 - val_accuracy: 0.8033\n",
            "Epoch 40/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1549 - accuracy: 0.9413 - val_loss: 0.6908 - val_accuracy: 0.8001\n",
            "Epoch 41/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1641 - accuracy: 0.9384 - val_loss: 0.6911 - val_accuracy: 0.8005\n",
            "Epoch 42/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1468 - accuracy: 0.9441 - val_loss: 0.6949 - val_accuracy: 0.7913\n",
            "Epoch 43/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1400 - accuracy: 0.9483 - val_loss: 0.6228 - val_accuracy: 0.8149\n",
            "Epoch 44/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1366 - accuracy: 0.9480 - val_loss: 0.6574 - val_accuracy: 0.8009\n",
            "Epoch 45/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.7197 - val_accuracy: 0.8022\n",
            "Epoch 46/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1280 - accuracy: 0.9527 - val_loss: 0.6518 - val_accuracy: 0.8097\n",
            "Epoch 47/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1230 - accuracy: 0.9566 - val_loss: 0.7705 - val_accuracy: 0.8099\n",
            "Epoch 48/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1107 - accuracy: 0.9583 - val_loss: 0.9412 - val_accuracy: 0.7952\n",
            "Epoch 49/50\n",
            "680/680 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9553 - val_loss: 0.8905 - val_accuracy: 0.8082\n",
            "Epoch 50/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1132 - accuracy: 0.9599 - val_loss: 0.7195 - val_accuracy: 0.8204\n",
            "Best epoch: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjhXUG4CjEoe",
        "outputId": "d77e21e5-f597-466a-e63a-17733ae3e18b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "680/680 [==============================] - 8s 5ms/step - loss: 1.2603 - accuracy: 0.4074 - val_loss: 1.0081 - val_accuracy: 0.5082\n",
            "Epoch 2/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 1.0054 - accuracy: 0.5202 - val_loss: 0.9766 - val_accuracy: 0.5418\n",
            "Epoch 3/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.9416 - accuracy: 0.5549 - val_loss: 0.9198 - val_accuracy: 0.5735\n",
            "Epoch 4/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.8811 - accuracy: 0.5847 - val_loss: 0.9581 - val_accuracy: 0.5628\n",
            "Epoch 5/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.8398 - accuracy: 0.6103 - val_loss: 0.8618 - val_accuracy: 0.5847\n",
            "Epoch 6/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.8025 - accuracy: 0.6325 - val_loss: 0.7784 - val_accuracy: 0.6459\n",
            "Epoch 7/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.7577 - accuracy: 0.6538 - val_loss: 0.7975 - val_accuracy: 0.6249\n",
            "Epoch 8/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.7377 - accuracy: 0.6625 - val_loss: 0.8062 - val_accuracy: 0.6426\n",
            "Epoch 9/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.6802 - accuracy: 0.6936 - val_loss: 0.7295 - val_accuracy: 0.6733\n",
            "Epoch 10/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.6487 - accuracy: 0.7053 - val_loss: 0.6979 - val_accuracy: 0.7025\n",
            "Epoch 11/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.6230 - accuracy: 0.7190 - val_loss: 0.7087 - val_accuracy: 0.6863\n",
            "Epoch 12/50\n",
            "680/680 [==============================] - 3s 5ms/step - loss: 0.5868 - accuracy: 0.7401 - val_loss: 0.6698 - val_accuracy: 0.7134\n",
            "Epoch 13/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.5586 - accuracy: 0.7567 - val_loss: 0.8487 - val_accuracy: 0.6860\n",
            "Epoch 14/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.5252 - accuracy: 0.7698 - val_loss: 0.6290 - val_accuracy: 0.7235\n",
            "Epoch 15/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4974 - accuracy: 0.7811 - val_loss: 0.6407 - val_accuracy: 0.7220\n",
            "Epoch 16/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4768 - accuracy: 0.7928 - val_loss: 0.6260 - val_accuracy: 0.7470\n",
            "Epoch 17/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4595 - accuracy: 0.8016 - val_loss: 0.7096 - val_accuracy: 0.7069\n",
            "Epoch 18/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4299 - accuracy: 0.8128 - val_loss: 0.6152 - val_accuracy: 0.7514\n",
            "Epoch 19/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.4059 - accuracy: 0.8273 - val_loss: 0.6023 - val_accuracy: 0.7590\n",
            "Epoch 20/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3942 - accuracy: 0.8306 - val_loss: 0.5988 - val_accuracy: 0.7557\n",
            "Epoch 21/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.3791 - accuracy: 0.8385 - val_loss: 0.6193 - val_accuracy: 0.7551\n",
            "Epoch 22/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3524 - accuracy: 0.8550 - val_loss: 0.6164 - val_accuracy: 0.7751\n",
            "Epoch 23/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3466 - accuracy: 0.8555 - val_loss: 0.5367 - val_accuracy: 0.7981\n",
            "Epoch 24/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.3169 - accuracy: 0.8655 - val_loss: 0.6532 - val_accuracy: 0.7755\n",
            "Epoch 25/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.3140 - accuracy: 0.8689 - val_loss: 0.6640 - val_accuracy: 0.7573\n",
            "Epoch 26/50\n",
            "680/680 [==============================] - 3s 5ms/step - loss: 0.2950 - accuracy: 0.8783 - val_loss: 0.6720 - val_accuracy: 0.7654\n",
            "Epoch 27/50\n",
            "680/680 [==============================] - 3s 5ms/step - loss: 0.2836 - accuracy: 0.8789 - val_loss: 0.6275 - val_accuracy: 0.7860\n",
            "Epoch 28/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.2815 - accuracy: 0.8875 - val_loss: 0.8290 - val_accuracy: 0.7632\n",
            "Epoch 29/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2640 - accuracy: 0.8923 - val_loss: 0.5856 - val_accuracy: 0.7830\n",
            "Epoch 30/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2500 - accuracy: 0.9004 - val_loss: 0.6026 - val_accuracy: 0.8003\n",
            "Epoch 31/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.2390 - accuracy: 0.9037 - val_loss: 0.6995 - val_accuracy: 0.7659\n",
            "Epoch 32/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.2349 - accuracy: 0.9066 - val_loss: 0.6737 - val_accuracy: 0.7591\n",
            "Epoch 33/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2155 - accuracy: 0.9140 - val_loss: 0.6086 - val_accuracy: 0.8033\n",
            "Epoch 34/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.2001 - accuracy: 0.9211 - val_loss: 0.6989 - val_accuracy: 0.7950\n",
            "Epoch 35/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.2033 - accuracy: 0.9202 - val_loss: 0.6393 - val_accuracy: 0.8062\n",
            "Epoch 36/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1973 - accuracy: 0.9231 - val_loss: 0.6235 - val_accuracy: 0.8018\n",
            "Epoch 37/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1808 - accuracy: 0.9309 - val_loss: 0.6669 - val_accuracy: 0.8101\n",
            "Epoch 38/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1972 - accuracy: 0.9234 - val_loss: 0.7112 - val_accuracy: 0.7823\n",
            "Epoch 39/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1790 - accuracy: 0.9307 - val_loss: 0.7025 - val_accuracy: 0.8042\n",
            "Epoch 40/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1542 - accuracy: 0.9422 - val_loss: 0.6870 - val_accuracy: 0.8053\n",
            "Epoch 41/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1592 - accuracy: 0.9405 - val_loss: 0.8512 - val_accuracy: 0.7698\n",
            "Epoch 42/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1471 - accuracy: 0.9433 - val_loss: 0.7625 - val_accuracy: 0.8082\n",
            "Epoch 43/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1457 - accuracy: 0.9465 - val_loss: 0.7321 - val_accuracy: 0.8114\n",
            "Epoch 44/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1380 - accuracy: 0.9483 - val_loss: 0.7397 - val_accuracy: 0.8033\n",
            "Epoch 45/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1361 - accuracy: 0.9483 - val_loss: 0.9269 - val_accuracy: 0.7875\n",
            "Epoch 46/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1337 - accuracy: 0.9504 - val_loss: 0.8620 - val_accuracy: 0.8071\n",
            "Epoch 47/50\n",
            "680/680 [==============================] - 3s 5ms/step - loss: 0.1163 - accuracy: 0.9566 - val_loss: 0.8991 - val_accuracy: 0.8038\n",
            "Epoch 48/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1248 - accuracy: 0.9548 - val_loss: 0.8226 - val_accuracy: 0.8088\n",
            "Epoch 49/50\n",
            "680/680 [==============================] - 4s 6ms/step - loss: 0.1326 - accuracy: 0.9526 - val_loss: 0.8193 - val_accuracy: 0.7972\n",
            "Epoch 50/50\n",
            "680/680 [==============================] - 4s 5ms/step - loss: 0.1058 - accuracy: 0.9634 - val_loss: 0.7821 - val_accuracy: 0.8093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7803869e3850>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(X_test, y_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOwpCmUorCHf",
        "outputId": "87fb6f3c-c44f-41bd-f7ac-427740c9a5a9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213/213 [==============================] - 1s 2ms/step - loss: 0.8034 - accuracy: 0.8075\n",
            "[test loss, test accuracy]: [0.8034020066261292, 0.8074716925621033]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoFzoIIJl3SZ",
        "outputId": "49f264bb-6f9f-4a3e-f0c3-8eb74d36f75f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 2352)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 424)               997672    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 424)               180200    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 424)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 4)                 1700      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,801,372\n",
            "Trainable params: 2,801,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4emC0CV_nv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}